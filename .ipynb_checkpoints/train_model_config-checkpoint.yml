activation: 'relu'
batch_size: 4500
dropout: 0.21992030005742
embedding_dim: 26
epochs: 100
learning_rate: 0.010685876950248729
lr_modifier: null
max_length: 50
max_words: 700
n_layers: 5
n_layers_gru: 1
optimizer: 'Adamax'
output_activation: null
nlp_models: 2
# Silence output
verbose: 1